{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concise Implementation of Dropout\n",
    "\n",
    "Using PyTorch, all we need to do is add a ``Dropout`` layer (also in the nn package) after each fully-connected layer,\n",
    "passing in the dropout probability as the only argument to its constructor. During training, the ``Dropout``\n",
    "layer will randomly drop out outputs of the previous layer (or equivalently, the inputs to the subsequent\n",
    "layer) according to the specified dropout probability. When PyTorch is not in training mode, the ``Dropout``\n",
    "layer simply passes the data through during testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "import d2l\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLayerNet(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens1, \n",
    "                 num_hiddens2, num_outputs):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \"\"\"\n",
    "        super(ThreeLayerNet, self).__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.linear1 = torch.nn.Linear(num_inputs, num_hiddens1)\n",
    "        self.linear2 = torch.nn.Linear(num_hiddens1, num_hiddens2)\n",
    "        self.linear3 = torch.nn.Linear(num_hiddens2, num_outputs)\n",
    "        self.nonlinear_func = torch.nn.ReLU()\n",
    "        # insert your code here\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return\n",
    "        a Tensor of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary (differentiable) operations on Tensors.\n",
    "        \"\"\"\n",
    "        h_relu1 = self.nonlinear_func(self.linear1(x.reshape(-1, self.num_inputs)))\n",
    "        # insert your code here\n",
    "        h_relu2 = self.nonlinear_func(self.linear2(h_relu1))\n",
    "        # insert your code here\n",
    "        y_pred = self.linear2(h_relu2)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_prob1, drop_prob2 = 0.2, 0.5\n",
    "\n",
    "net = ThreeLayerNet(num_inputs=784, num_hiddens1=256,\n",
    "                  num_hiddens2=256, num_outputs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_iter, test_iter = utils.load_data_fashion_mnist(batch_size)\n",
    "num_epochs, lr = 10, 0.5\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "utils.train(net, train_iter, test_iter, loss, num_epochs, \n",
    "            optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.predict(net, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
